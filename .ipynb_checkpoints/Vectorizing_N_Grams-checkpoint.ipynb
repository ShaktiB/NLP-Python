{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Raw Data: N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import string \n",
    "import re\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ss = nltk.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0  spam   \n",
       "1   ham   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \n",
       "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "1                                        Nah I don't think he goes to usf, he lives around here though  \n",
       "2                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
       "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  \n",
       "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.tsv', sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = ''.join([word.lower() for word in text if word not in string.punctuation]) # Remove punctuation\n",
    "    tokens = re.split('\\W+',text) # Tokenize: Split on any character that is not alphanumeric\n",
    "    text = ' '.join([ss.stem(word) for word in tokens if word not in stopwords]) # Remove stopwords & stem\n",
    "    #text = [ss.stem(word) for word in tokenized_text] # Stemming\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 21st may 2005 text fa 87121 receiv entri questionst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>date sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...</td>\n",
       "      <td>per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0  spam   \n",
       "1   ham   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \\\n",
       "0  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "1                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "2                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "3                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "4  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your call...   \n",
       "\n",
       "                                                                                          cleaned_text  \n",
       "0  free entri 2 wkli comp win fa cup final tkts 21st may 2005 text fa 87121 receiv entri questionst...  \n",
       "1                                                            nah dont think goe usf live around though  \n",
       "2                                                        even brother like speak treat like aid patent  \n",
       "3                                                                                          date sunday  \n",
       "4  per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'] = data['body_text'].apply(lambda x: clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply CountVectorizer (w/ N-Grams) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on smaller dataset to make it easy to visualize the implementation\n",
    "data_sample = data[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer outputs a sparse matrix\n",
    "- A ***sparse matrix***: A matric in which most elements are 0. In the interest of efficient storage, a sparse matrix will be stored by only storing the locations of the non-zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5567, 31275)\n"
     ]
    }
   ],
   "source": [
    "bi_gram = CountVectorizer(ngram_range=(2,2))\n",
    "xcounts = bi_gram.fit_transform(data['cleaned_text'])\n",
    "\n",
    "print(xcounts.shape)\n",
    "#print(bi_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 198)\n",
      "['09061701461 claim', '100 20000', '100000 prize', '11 month', '12 hour', '150pday 6day', '16 tsandc', '20000 pound', '2005 text', '21st may', '4txtú120 poboxox36504w45wq', '6day 16', '81010 tc', '87077 eg', '87077 trywal', '87121 receiv', '87575 cost', '900 prize', 'aft finish', 'aid patent', 'alright way', 'anymor tonight', 'appli 08452810075over18', 'appli repli', 'ard smth', 'around though', 'brother like', 'call 09061701461', 'call mobil', 'caller press', 'callertun caller', 'camera free', 'cash 100', 'chanc win', 'claim 81010', 'claim call', 'claim code', 'click httpwap', 'click wap', 'co free', 'code kl341', 'colour mobil', 'comp win', 'copi friend', 'cost 150pday', 'credit click', 'cri enough', 'csh11 send', 'cup final', 'custom select', 'da stock', 'date sunday', 'dont miss', 'dont think', 'dont want', 'eg england', 'eh rememb', 'england 87077', 'england macedonia', 'enough today', 'entitl updat', 'entri questionstd', 'entri wkli', 'even brother', 'fa 87121', 'fa cup', 'feel way', 'ffffffffff alright', 'final tkts', 'fine way', 'finish lunch', 'finish ur', 'first lar', 'free 08002986030', 'free call', 'free entri', 'free membership', 'friend callertun', 'go str', 'go tri', 'goalsteam news', 'goe usf', 'gonna home', 'ha ha', 'ha joke', 'hl info', 'home soon', 'httpwap xxxmobilemovieclubcomnqjkgighjjgcbl', 'im gonna', 'ive cri', 'jackpot txt', 'kim watch', 'kl341 valid', 'lar da', 'latest colour', 'lccltd pobox', 'like aid', 'like speak', 'link next', 'live around', 'lor ard', 'lor finish', 'lunch alreadi', 'lunch go', 'macedonia dont', 'make wet', 'may 2005', 'meet sooner', 'mell mell', 'mell oru', 'membership 100000', 'messag click', 'minnaminungint nurungu', 'miss goalsteam', 'mobil 11', 'mobil camera', 'mobil updat', 'month entitl', 'month ha', 'nah dont', 'name yes', 'nation team', 'naughti make', 'network custom', 'news txt', 'next txt', 'nurungu vettam', 'oh kim', 'oru minnaminungint', 'pay first', 'per request', 'pobox 4403ldnw1a7rw18', 'poboxox36504w45wq 16', 'pound txt', 'press copi', 'prize jackpot', 'prize reward', 'questionstd txt', 'ratetc appli', 'receiv entri', 'receivea 900', 'rememb spell', 'repli hl', 'request mell', 'reward claim', 'scotland 4txtú120', 'select receivea', 'send 87575', 'serious spell', 'set callertun', 'six chanc', 'smth lor', 'soon dont', 'speak treat', 'spell name', 'stock comin', 'str lor', 'stuff anymor', 'talk stuff', 'tc wwwdbuknet', 'team 87077', 'text fa', 'think goe', 'tkts 21st', 'tonight ive', 'treat like', 'tri month', 'trywal scotland', 'tsandc appli', 'txt csh11', 'txt messag', 'txt ratetc', 'txt ur', 'txt word', 'updat co', 'updat latest', 'ur lunch', 'ur nation', 'urgent week', 'use credit', 'usf live', 'valid 12', 'valu network', 'vettam set', 'want talk', 'wap link', 'way feel', 'way gota', 'way meet', 'week free', 'win cash', 'win fa', 'winner valu', 'wkli comp', 'word claim', 'wwwdbuknet lccltd', 'xxxmobilemovieclub use', 'yes naughti']\n"
     ]
    }
   ],
   "source": [
    "# Sample on smaller data\n",
    "\n",
    "bigram_sample = CountVectorizer(ngram_range=(2,2))\n",
    "xcounts_sample = bigram_sample.fit_transform(data_sample['cleaned_text'])\n",
    "\n",
    "print(xcounts_sample.shape)\n",
    "print(bigram_sample.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>008704050406 sp</th>\n",
       "      <th>0089mi last</th>\n",
       "      <th>0121 2025050</th>\n",
       "      <th>01223585236 xx</th>\n",
       "      <th>01223585334 cum</th>\n",
       "      <th>0125698789 ring</th>\n",
       "      <th>02 user</th>\n",
       "      <th>020603 2nd</th>\n",
       "      <th>0207 153</th>\n",
       "      <th>02072069400 bx</th>\n",
       "      <th>...</th>\n",
       "      <th>zoe 18</th>\n",
       "      <th>zoe hit</th>\n",
       "      <th>zogtorius stare</th>\n",
       "      <th>zoom cine</th>\n",
       "      <th>zouk nichol</th>\n",
       "      <th>zyada kisi</th>\n",
       "      <th>üll finish</th>\n",
       "      <th>üll submit</th>\n",
       "      <th>üll take</th>\n",
       "      <th>〨ud even</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   008704050406 sp  0089mi last  0121 2025050  01223585236 xx  \\\n",
       "0                0            0             0               0   \n",
       "1                0            0             0               0   \n",
       "2                0            0             0               0   \n",
       "3                0            0             0               0   \n",
       "4                0            0             0               0   \n",
       "\n",
       "   01223585334 cum  0125698789 ring  02 user  020603 2nd  0207 153  \\\n",
       "0                0                0        0           0         0   \n",
       "1                0                0        0           0         0   \n",
       "2                0                0        0           0         0   \n",
       "3                0                0        0           0         0   \n",
       "4                0                0        0           0         0   \n",
       "\n",
       "   02072069400 bx  ...  zoe 18  zoe hit  zogtorius stare  zoom cine  \\\n",
       "0               0  ...       0        0                0          0   \n",
       "1               0  ...       0        0                0          0   \n",
       "2               0  ...       0        0                0          0   \n",
       "3               0  ...       0        0                0          0   \n",
       "4               0  ...       0        0                0          0   \n",
       "\n",
       "   zouk nichol  zyada kisi  üll finish  üll submit  üll take  〨ud even  \n",
       "0            0           0           0           0         0         0  \n",
       "1            0           0           0           0         0         0  \n",
       "2            0           0           0           0         0         0  \n",
       "3            0           0           0           0         0         0  \n",
       "4            0           0           0           0         0         0  \n",
       "\n",
       "[5 rows x 31275 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(xcounts.toarray())\n",
    "df.columns = bi_gram.get_feature_names()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
